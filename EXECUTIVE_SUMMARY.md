# Students' Perception, Trust, and Ethical Awareness of AI Tools in Education

The study examines **students' perception, trust, and ethical awareness of AI tools in education**, focusing on usage patterns, trust levels, ethical concerns, verification behaviors, and future outlook on AI skills across diverse degree programs and year levels.

## Methodology
**Simple Random Sampling** ensured equal selection probability, minimizing bias across year levels (1-5) and 20+ degree programs. **41 responses** collected Nov 23-24, 2025 via **Google Forms** (ease of distribution, multi-device access, automatic recording, anonymity). Analysis used Python (pandas, matplotlib, seaborn) for quantitative analysis and theme extraction from open-ended questions.

**Limitations:**

• **Nonresponse Bias:** Only internet-accessible, willing participants responded.

• **Response Quality:** ~15% vague entries ("NA," "Idk").

• **Sample Size:** n=41, limited statistical power.

• **Discipline Bias:** Majority CS students.

• **Cross-Sectional:** Snapshot; no causality/longitudinal tracking.

• **Self-Reported:** No objective verification.

Despite limitations, data shows **100% alignment** between methodology themes, computational analysis, and quantitative findings.

## Key Findings
**Adoption:** 80% very/extremely familiar; 60% use often/daily; ChatGPT 85%, Gemini 44%, Copilot 22%; 73% used 1+ year.

**Value:** 75% very/extremely helpful; 70% agree AI improves learning; valued for understanding complex concepts, 24/7 access.

**Trust:** 76% rate "moderately accurate"; 73% always/often verify; 85% concerned about misinformation; **source transparency #1 factor** (19 mentions).

**Ethics:** 78% worry plagiarism; 80% want school guidelines; concerns: over-reliance→critical thinking (7), privacy/data (13), plagiarism (4).

**Future:** 75% AI skills career-critical; 91% interested in courses; want: prompt engineering (6), responsible use (5), data analysis (5), ML (4).

**Open-Ended Themes:** *Learning*—easier understanding (14), quick info (9), faster (13). *Trust*—sources (19), reliable (6), consistency (7). *Improvements*—citations (11), accuracy (19), clarity (4), privacy (3).

## Results and Discussion
**Institutions:** (1) Clear AI policies (80% request), (2) AI literacy curriculum—prompt engineering/verification, (3) Anti-over-reliance assignments, (4) Responsible use training.

**Developers:** (1) Source transparency—citations/confidence levels (most requested), (2) Accuracy—reduce hallucinations, (3) Educational features—"Study Buddy" modes, (4) Privacy protections.

**Researchers:** (1) Diverse samples beyond CS, (2) Longitudinal studies—AI impact over time, (3) Test interventions (literacy programs/policies), (4) Cross-institutional validation.

## Critical Insight
Students show **sophisticated AI literacy**—high use (60% often/daily) + **healthy skepticism** (73% verify, 85% concerned). They recognize value but demand **accountability, transparency, guidelines**. Overwhelming citation requests (19) signal desire to learn *with* AI, not just *from* it. Institutions should formalize integration with policies, literacy training, and verification-promoting tools.
